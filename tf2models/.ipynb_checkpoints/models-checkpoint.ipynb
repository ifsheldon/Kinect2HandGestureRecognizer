{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use tensorflow 2.0\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_net_path = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "mobile_net = hub.KerasLayer(mobile_net_path,output_shape = [1280] , trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old-fashioned way of managing data\n",
    "def load_pictures(path):\n",
    "    pictures = []\n",
    "    os.chdir(path)\n",
    "    print(\"changed working dir\")\n",
    "    picture_paths = np.array(os.listdir())\n",
    "    picture_paths = shuffle(picture_paths)\n",
    "    for path in tqdm(picture_paths[:1800]):\n",
    "        pictures.append(mpimg.imread(path).astype(np.float16))\n",
    "    pictures = np.array(pictures)\n",
    "    pictures = np.expand_dims(pictures, axis=-1)\n",
    "    return pictures\n",
    "def shuffle(arr):\n",
    "    l = len(arr)\n",
    "    indices = np.arange(l)\n",
    "    np.random.shuffle(indices)\n",
    "    arr = arr[indices]\n",
    "    return arr\n",
    "def get_batch(data, batch_size, shuff = True):\n",
    "    if shuff:\n",
    "        data = shuffle(data)\n",
    "    length = len(data)\n",
    "    batches = length//batch_size\n",
    "    for i in range(batches):\n",
    "        batch = data[i*batch_size:(i+1)*batch_size]\n",
    "        yield batch\n",
    "\n",
    "# advanced data generator\n",
    "# for mode,see https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow_from_directory\n",
    "def get_data_iterator(dir_path, mode, batch_size):\n",
    "    datagen = K.preprocessing.image.ImageDataGenerator(dtype=tf.float16)\n",
    "    data = datagen.flow_from_directory(dir_path, target_size = (1024,1024),color_mode = \"grayscale\",batch_size = batch_size,class_mode=mode)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_rate = 15\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolation_layer(X):\n",
    "    X1 = tf.image.resize(X,(224,224),method=tf.image.ResizeMethod.BILINEAR)\n",
    "    X2 = tf.image.resize(X,(224,224),method=tf.image.ResizeMethod.BICUBIC,antialias=True)\n",
    "    X3 = tf.image.resize(X,(224,224),method=tf.image.ResizeMethod.GAUSSIAN)\n",
    "    X = K.layers.Concatenate(axis=-1)([X1,X2,X3])\n",
    "    return X\n",
    "\n",
    "def encoder_layer(X):\n",
    "    X = tf.image.resize(X,(512,512),method=tf.image.ResizeMethod.BILINEAR)\n",
    "    X = K.layers.Conv2D(filters=1,kernel_size=1,strides=1,use_bias=True,padding=\"valid\",name =\"mask\",kernel_regularizer=K.regularizers.l2(l=0.01))(X)\n",
    "    X = K.layers.BatchNormalization(name=\"bias\")(X)\n",
    "    X = K.layers.Activation(\"relu\")(X)\n",
    "    # input shape = (512,512,1)\n",
    "    X = K.layers.Conv2D(filters=4, kernel_size=(3,3), strides=(1,1),padding=\"valid\",kernel_initializer=\"he_normal\",kernel_regularizer=K.regularizers.l2(l=0.01))(X)\n",
    "    X = K.layers.BatchNormalization(name=\"bn1\")(X)\n",
    "    X = K.layers.Activation(\"selu\")(X)\n",
    "\n",
    "    # input shape = (510,510,4)\n",
    "    X = K.layers.MaxPool2D((2,2),name=\"max_pool1\",padding=\"valid\",strides=(2,2))(X)\n",
    "\n",
    "    # input shape = (255,255,4)\n",
    "    X = K.layers.Conv2D(filters=8,kernel_size=(4,4),strides=1,padding=\"valid\",kernel_initializer=\"he_normal\",kernel_regularizer=K.regularizers.l2(l=0.01))(X)\n",
    "    X = K.layers.BatchNormalization(name=\"bn2\")(X)\n",
    "    X = K.layers.Activation(\"selu\")(X)\n",
    "    # input shape = (252,252,8)\n",
    "    X = K.layers.MaxPool2D((2,2),name=\"max_pool2\",padding=\"valid\",strides=(1,1))(X)\n",
    "\n",
    "    # input shape = (251,251,8)\n",
    "    X = K.layers.Conv2D(filters=12,kernel_size=(5,5),strides=1,padding=\"valid\",kernel_initializer=\"he_normal\",kernel_regularizer=K.regularizers.l2(l=0.01))(X)\n",
    "    X = K.layers.BatchNormalization(name=\"bn3\")(X)\n",
    "    X = K.layers.Activation(\"selu\")(X)\n",
    "    # input shape = (247,247,16)\n",
    "    X = K.layers.MaxPool2D((2,2),name=\"max_pool3\",padding=\"valid\",strides=(1,1))(X)\n",
    "\n",
    "    # input shape = (246,246,16)\n",
    "    X = K.layers.Conv2D(filters=16,kernel_size=(7,7),strides=1,padding=\"valid\",kernel_initializer=\"he_normal\",kernel_regularizer=K.regularizers.l2(l=0.01))(X)\n",
    "    X = K.layers.BatchNormalization(name=\"bn4\")(X)\n",
    "    X = K.layers.Activation(\"selu\")(X)\n",
    "    # input shape = (240,240,32)\n",
    "    X = K.layers.MaxPool2D((2,2),name=\"max_pool4\",padding=\"valid\",strides=(1,1))(X)\n",
    "\n",
    "    # input shape = (239,239,32)\n",
    "    X = K.layers.Conv2D(filters=20,kernel_size=(8,8),strides=1,padding=\"valid\",kernel_initializer=\"he_normal\",kernel_regularizer=K.regularizers.l2(l=0.01))(X)\n",
    "    X = K.layers.BatchNormalization(name=\"bn5\")(X)\n",
    "    X = K.layers.Activation(\"selu\")(X)\n",
    "\n",
    "    # input shape = (232,232,64)\n",
    "    X = K.layers.Conv2D(filters=3,kernel_size=(9,9),strides=1,padding=\"valid\",kernel_initializer=\"he_normal\",kernel_regularizer=K.regularizers.l2(l=0.01))(X)\n",
    "    X = K.layers.BatchNormalization(name=\"bn6\")(X)\n",
    "    X = K.layers.Activation(\"selu\")(X)\n",
    "    # output shape = (224,224,3)\n",
    "    return X\n",
    "\n",
    "def decoder_layer(X):\n",
    "    # input shape = (224,224,3)\n",
    "    D = tf.image.resize(X,size=(256,256))\n",
    "    # input shape = (256,256,3)\n",
    "    D = K.layers.Conv2DTranspose(filters=6,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\")(D)\n",
    "    # input shape = (512,512,6)\n",
    "    D = K.layers.Conv2DTranspose(filters=1,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\")(D)\n",
    "    # output (1024,1024,1)\n",
    "    return D\n",
    "\n",
    "def rnn_layer(X):\n",
    "    R = K.layers.LSTM(units=128,return_sequences=True)(X)\n",
    "    R = K.layers.Dropout(rate=0.5)(R)\n",
    "    R = K.layers.BatchNormalization(name=\"bn1_rnn\")(R)\n",
    "    \n",
    "    R = K.layers.LSTM(units=128,return_sequences=True)(R)\n",
    "    R = K.layers.Dropout(rate=0.5)(R)\n",
    "    R = K.layers.BatchNormalization(name = \"bn2_rnn\")(R)\n",
    "    R = K.layers.TimeDistributed(K.layers.Dense(3,activation=\"softmax\"))(R)\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(batch, frame, C, H, W)->(batch*frame, C, H, W)->CNN->(batch*frame, feature)->(batch, frame, feature)->RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recognizer_without_encoder\n",
    "input_images = K.layers.Input(shape=(1024,1024,1),batch_size=batch_size*frame_rate)\n",
    "X = interpolation_layer(input_images)\n",
    "X = mobile_net(X)\n",
    "X = tf.reshape(X,(-1,frame_rate,1280))\n",
    "R = rnn_layer(X)\n",
    "preds = tf.reshape(R,(-1,3))\n",
    "recognizer_without_encoder = K.Model(inputs = input_images, outputs = preds, name=\"recognizer_without_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer_without_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recogizer_with_encoder\n",
    "input_images = K.layers.Input(shape=(1024,1024,1),batch_size=batch_size*frame_rate)\n",
    "E = encoder_layer(input_images)\n",
    "D = decoder_layer(E)\n",
    "M = mobile_net(E)\n",
    "X = tf.reshape(M,(-1,frame_rate,1280))\n",
    "R = rnn_layer(X)\n",
    "preds = tf.reshape(R,(-1,3))\n",
    "recognizer_with_encoder = K.Model(inputs = input_images, outputs = preds, name =\"recognizer_with_encoder\" )\n",
    "autoencoder = K.Model(inputs = input_images, outputs = D, name=\"autoencoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for save and load, see https://www.tensorflow.org/tutorials/keras/save_and_load"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
