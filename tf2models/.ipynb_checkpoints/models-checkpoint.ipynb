{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use tensorflow 2.0\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_net_path = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "mobile_net = hub.KerasLayer(mobile_net_path,output_shape = [1280] , trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old-fashioned way of managing data\n",
    "def load_pictures(path):\n",
    "    pictures = []\n",
    "    os.chdir(path)\n",
    "    print(\"changed working dir\")\n",
    "    picture_paths = np.array(os.listdir())\n",
    "    picture_paths = shuffle(picture_paths)\n",
    "    for path in tqdm(picture_paths[:1800]):\n",
    "        pictures.append(mpimg.imread(path).astype(np.float16))\n",
    "    pictures = np.array(pictures)\n",
    "    pictures = np.expand_dims(pictures, axis=-1)\n",
    "    return pictures\n",
    "def shuffle(arr):\n",
    "    l = len(arr)\n",
    "    indices = np.arange(l)\n",
    "    np.random.shuffle(indices)\n",
    "    arr = arr[indices]\n",
    "    return arr\n",
    "def get_batch(data, batch_size, shuff = True):\n",
    "    if shuff:\n",
    "        data = shuffle(data)\n",
    "    length = len(data)\n",
    "    batches = length//batch_size\n",
    "    for i in range(batches):\n",
    "        batch = data[i*batch_size:(i+1)*batch_size]\n",
    "        yield batch\n",
    "\n",
    "# advanced data generator\n",
    "# for mode,see https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow_from_directory\n",
    "def get_data_iterator(dir_path, mode, batch_size):\n",
    "    datagen = K.preprocessing.image.ImageDataGenerator(dtype=tf.float16,rescale = 1/255)\n",
    "    data = datagen.flow_from_directory(dir_path, \n",
    "                                       target_size = (1024,1024),\n",
    "                                       color_mode = \"grayscale\",\n",
    "                                       batch_size = batch_size,\n",
    "                                       shuffle = False, # keep sequence\n",
    "                                       class_mode=mode)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_rate = 15\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolation_layer(X):\n",
    "    X1 = tf.image.resize(X,(224,224),method=tf.image.ResizeMethod.BILINEAR)\n",
    "    X2 = tf.image.resize(X,(224,224),method=tf.image.ResizeMethod.BICUBIC,antialias=True)\n",
    "    X3 = tf.image.resize(X,(224,224),method=tf.image.ResizeMethod.GAUSSIAN)\n",
    "    X = K.layers.Concatenate(axis=-1)([X1,X2,X3])\n",
    "    return X\n",
    "\n",
    "def encoder_layer(X):\n",
    "    X = tf.image.resize(X,(512,512),method=tf.image.ResizeMethod.BILINEAR)\n",
    "    X = K.layers.Conv2D(filters=1,kernel_size=1,strides=1,use_bias=True,padding=\"valid\",name =\"mask\",kernel_regularizer=K.regularizers.l2(l=0.01))(X)\n",
    "    X = K.layers.BatchNormalization(name=\"bias\")(X)\n",
    "    X = K.layers.Activation(\"relu\")(X)\n",
    "    # input shape = (512,512,1)\n",
    "    X = K.layers.Conv2D(filters=4, kernel_size=(3,3), strides=(1,1),padding=\"valid\",kernel_initializer=\"he_normal\",kernel_regularizer=K.regularizers.l2(l=0.01))(X)\n",
    "    X = K.layers.BatchNormalization(name=\"bn1\")(X)\n",
    "    X = K.layers.Activation(\"selu\")(X)\n",
    "\n",
    "    # input shape = (510,510,4)\n",
    "    X = K.layers.MaxPool2D((2,2),name=\"max_pool1\",padding=\"valid\",strides=(2,2))(X)\n",
    "\n",
    "    # input shape = (255,255,4)\n",
    "    X = K.layers.Conv2D(filters=8,kernel_size=(4,4),strides=1,padding=\"valid\",kernel_initializer=\"he_normal\",kernel_regularizer=K.regularizers.l2(l=0.01))(X)\n",
    "    X = K.layers.BatchNormalization(name=\"bn2\")(X)\n",
    "    X = K.layers.Activation(\"selu\")(X)\n",
    "    # input shape = (252,252,8)\n",
    "    X = K.layers.MaxPool2D((2,2),name=\"max_pool2\",padding=\"valid\",strides=(1,1))(X)\n",
    "\n",
    "    # input shape = (251,251,8)\n",
    "    X = K.layers.Conv2D(filters=12,kernel_size=(5,5),strides=1,padding=\"valid\",kernel_initializer=\"he_normal\",kernel_regularizer=K.regularizers.l2(l=0.01))(X)\n",
    "    X = K.layers.BatchNormalization(name=\"bn3\")(X)\n",
    "    X = K.layers.Activation(\"selu\")(X)\n",
    "    # input shape = (247,247,16)\n",
    "    X = K.layers.MaxPool2D((2,2),name=\"max_pool3\",padding=\"valid\",strides=(1,1))(X)\n",
    "\n",
    "    # input shape = (246,246,16)\n",
    "    X = K.layers.Conv2D(filters=16,kernel_size=(7,7),strides=1,padding=\"valid\",kernel_initializer=\"he_normal\",kernel_regularizer=K.regularizers.l2(l=0.01))(X)\n",
    "    X = K.layers.BatchNormalization(name=\"bn4\")(X)\n",
    "    X = K.layers.Activation(\"selu\")(X)\n",
    "    # input shape = (240,240,32)\n",
    "    X = K.layers.MaxPool2D((2,2),name=\"max_pool4\",padding=\"valid\",strides=(1,1))(X)\n",
    "\n",
    "    # input shape = (239,239,32)\n",
    "    X = K.layers.Conv2D(filters=20,kernel_size=(8,8),strides=1,padding=\"valid\",kernel_initializer=\"he_normal\",kernel_regularizer=K.regularizers.l2(l=0.01))(X)\n",
    "    X = K.layers.BatchNormalization(name=\"bn5\")(X)\n",
    "    X = K.layers.Activation(\"selu\")(X)\n",
    "\n",
    "    # input shape = (232,232,64)\n",
    "    X = K.layers.Conv2D(filters=3,kernel_size=(9,9),strides=1,padding=\"valid\",kernel_initializer=\"he_normal\",kernel_regularizer=K.regularizers.l2(l=0.01))(X)\n",
    "    X = K.layers.BatchNormalization(name=\"bn6\")(X)\n",
    "    X = K.layers.Activation(\"selu\")(X)\n",
    "    # output shape = (224,224,3)\n",
    "    return X\n",
    "\n",
    "def decoder_layer(X):\n",
    "    # input shape = (224,224,3)\n",
    "    D = tf.image.resize(X,size=(256,256))\n",
    "    # input shape = (256,256,3)\n",
    "    D = K.layers.Conv2DTranspose(filters=6,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\")(D)\n",
    "    # input shape = (512,512,6)\n",
    "    D = K.layers.Conv2DTranspose(filters=1,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\")(D)\n",
    "    # output (1024,1024,1)\n",
    "    return D\n",
    "\n",
    "def rnn_layer(X):\n",
    "    R = K.layers.LSTM(units=128,return_sequences=True,kernel_regularizer=K.regularizers.l2(l=0.01))(X)\n",
    "    R = K.layers.Dropout(rate=0.5)(R)\n",
    "    R = K.layers.BatchNormalization(name=\"bn1_rnn\")(R)\n",
    "    \n",
    "    R = K.layers.LSTM(units=128,return_sequences=True,kernel_regularizer=K.regularizers.l2(l=0.01))(R)\n",
    "    R = K.layers.Dropout(rate=0.5)(R)\n",
    "    R = K.layers.BatchNormalization(name = \"bn2_rnn\")(R)\n",
    "    R = K.layers.TimeDistributed(K.layers.Dense(4,activation=\"softmax\"))(R)\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(batch, frame, C, H, W)->(batch*frame, C, H, W)->CNN->(batch*frame, feature)->(batch, frame, feature)->RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output tf_op_layer_rrr_2 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to tf_op_layer_rrr_2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output tf_op_layer_rrr_2 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to tf_op_layer_rrr_2.\n"
     ]
    }
   ],
   "source": [
    "# recognizer_without_encoder\n",
    "input_images = K.layers.Input(shape=(1024,1024,1),batch_size=batch_size*frame_rate)\n",
    "X = interpolation_layer(input_images)\n",
    "# The input images are expected to have color values in the range [0,1]\n",
    "X = mobile_net(X)\n",
    "X = tf.reshape(X,(-1,frame_rate,1280))\n",
    "R = rnn_layer(X)\n",
    "preds = tf.reshape(R,(-1,4),name = \"rrr\") ###???tensorflow:Output tf_op_layer_rrr missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to tf_op_layer_rrr.\n",
    "recognizer_without_encoder = K.Model(inputs = input_images, outputs = preds, name=\"recognizer_without_encoder\")\n",
    "recognizer_without_encoder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer_without_encoder.summary(optimizer=\"adam\",loss = K.losses.CategoricalCrossentropy(), metrics=[K.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recogizer_with_encoder\n",
    "input_images = K.layers.Input(shape=(1024,1024,1),batch_size=batch_size*frame_rate)\n",
    "E = encoder_layer(input_images)\n",
    "D = decoder_layer(E)\n",
    "M = mobile_net(E)\n",
    "X = tf.reshape(M,(-1,frame_rate,1280))\n",
    "R = rnn_layer(X)\n",
    "preds = tf.reshape(R,(-1,4))\n",
    "recognizer_with_encoder = K.Model(inputs = input_images, outputs = preds, name =\"recognizer_with_encoder\" )\n",
    "recognizer_with_encoder.compile(optimizer=\"adam\",loss = K.losses.CategoricalCrossentropy(), metrics=[K.metrics.CategoricalAccuracy()])\n",
    "autoencoder = K.Model(inputs = input_images, outputs = D, name=\"autoencoder\")\n",
    "autoencoder.compile(optimizer=\"adam\",loss=K.losses.MeanSquaredError(),metrics=[K.metrics.MeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"recognizer_without_encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(150, 1024, 1024, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_resize_14/Shape (Te [(4,)]               0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_resize_15/Shape (Te [(4,)]               0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_resize_14/strided_s [(2,)]               0           tf_op_layer_resize_14/Shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_resize_15/strided_s [(2,)]               0           tf_op_layer_resize_15/Shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_resize_14/Cast (Ten [(2,)]               0           tf_op_layer_resize_14/strided_sli\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_resize_15/Cast (Ten [(2,)]               0           tf_op_layer_resize_15/strided_sli\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_resize_14/truediv ( [(2,)]               0           tf_op_layer_resize_14/Cast[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_resize_15/truediv ( [(2,)]               0           tf_op_layer_resize_15/Cast[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_resize_13/ResizeBil [(150, 224, 224, 1)] 0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_resize_14/ScaleAndT [(150, 224, 224, 1)] 0           input_6[0][0]                    \n",
      "                                                                 tf_op_layer_resize_14/truediv[0][\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_resize_15/ScaleAndT [(150, 224, 224, 1)] 0           input_6[0][0]                    \n",
      "                                                                 tf_op_layer_resize_15/truediv[0][\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (150, 224, 224, 3)   0           tf_op_layer_resize_13/ResizeBilin\n",
      "                                                                 tf_op_layer_resize_14/ScaleAndTra\n",
      "                                                                 tf_op_layer_resize_15/ScaleAndTra\n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        (150, 1280)          2257984     concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_8 (TensorFl [(10, 15, 1280)]     0           keras_layer[5][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_10 (LSTM)                  (10, 15, 128)        721408      tf_op_layer_Reshape_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (10, 15, 128)        0           lstm_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn1_rnn (BatchNormalization)    (10, 15, 128)        512         dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_11 (LSTM)                  (10, 15, 128)        131584      bn1_rnn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (10, 15, 128)        0           lstm_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn2_rnn (BatchNormalization)    (10, 15, 128)        512         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (10, 15, 4)          516         bn2_rnn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_rrr_2 (TensorFlowOp [(150, 4)]           0           time_distributed_5[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 3,112,516\n",
      "Trainable params: 854,020\n",
      "Non-trainable params: 2,258,496\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "recognizer_without_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"recognizer_with_encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(150, 1024, 1024, 1)]    0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_resize_16/Resize [(150, 512, 512, 1)]      0         \n",
      "_________________________________________________________________\n",
      "mask (Conv2D)                (150, 512, 512, 1)        2         \n",
      "_________________________________________________________________\n",
      "bias (BatchNormalization)    (150, 512, 512, 1)        4         \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (150, 512, 512, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (150, 510, 510, 4)        40        \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (150, 510, 510, 4)        16        \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (150, 510, 510, 4)        0         \n",
      "_________________________________________________________________\n",
      "max_pool1 (MaxPooling2D)     (150, 255, 255, 4)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (150, 252, 252, 8)        520       \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (150, 252, 252, 8)        32        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (150, 252, 252, 8)        0         \n",
      "_________________________________________________________________\n",
      "max_pool2 (MaxPooling2D)     (150, 251, 251, 8)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (150, 247, 247, 12)       2412      \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (150, 247, 247, 12)       48        \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (150, 247, 247, 12)       0         \n",
      "_________________________________________________________________\n",
      "max_pool3 (MaxPooling2D)     (150, 246, 246, 12)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (150, 240, 240, 16)       9424      \n",
      "_________________________________________________________________\n",
      "bn4 (BatchNormalization)     (150, 240, 240, 16)       64        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (150, 240, 240, 16)       0         \n",
      "_________________________________________________________________\n",
      "max_pool4 (MaxPooling2D)     (150, 239, 239, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (150, 232, 232, 20)       20500     \n",
      "_________________________________________________________________\n",
      "bn5 (BatchNormalization)     (150, 232, 232, 20)       80        \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (150, 232, 232, 20)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (150, 224, 224, 3)        4863      \n",
      "_________________________________________________________________\n",
      "bn6 (BatchNormalization)     (150, 224, 224, 3)        12        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (150, 224, 224, 3)        0         \n",
      "_________________________________________________________________\n",
      "keras_layer (KerasLayer)     (150, 1280)               2257984   \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape_9 (Tenso [(10, 15, 1280)]          0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (10, 15, 128)             721408    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (10, 15, 128)             0         \n",
      "_________________________________________________________________\n",
      "bn1_rnn (BatchNormalization) (10, 15, 128)             512       \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (10, 15, 128)             131584    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (10, 15, 128)             0         \n",
      "_________________________________________________________________\n",
      "bn2_rnn (BatchNormalization) (10, 15, 128)             512       \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (10, 15, 4)               516       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape_10 (Tens [(150, 4)]                0         \n",
      "=================================================================\n",
      "Total params: 3,150,533\n",
      "Trainable params: 891,909\n",
      "Non-trainable params: 2,258,624\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "recognizer_with_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for save and load, see https://www.tensorflow.org/tutorials/keras/save_and_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_data_iterator(\"C:/Onedrive/Study/Experiment/data_for_autoencoder\",\"input\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = next(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(d[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.reshape(d[0],(1024,1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
